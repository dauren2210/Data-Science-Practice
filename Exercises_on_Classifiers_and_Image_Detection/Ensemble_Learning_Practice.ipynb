{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTiwdsdtaWF-"
   },
   "source": [
    "## Dauren Tursynbek \n",
    "## Machine Learning Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaXfthumaUSE"
   },
   "source": [
    "# Practical Task on Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uSJilULIiUDq"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from tensorflow.keras import  Model\n",
    "from tensorflow.keras.layers import Conv2DTranspose,Conv2D, concatenate, Input,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P96F-eEIIhj0"
   },
   "source": [
    "##### **Malware detection refers to the process of detecting the presence of malware on a host system or of distin-guishing whether a specific program is 'malicious' or 'benign'. In this task, you will use some network layer features such as Duration, Number of packets, etc. to build a machine learning classification model that will detect Android malware applications, using app features.**\n",
    "**Read data in Python. Split your data into train and test sets (80% and 20% respectively).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Gpa7pm9taaxG"
   },
   "outputs": [],
   "source": [
    "# importing dataset files\n",
    "data = pd.read_csv('android_traffic.csv')\n",
    "# defining X with values of first columns\n",
    "X = data.iloc[:,:10]\n",
    "# defining Y with values of last column\n",
    "y = data[['type']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJYEY4QpI1M8"
   },
   "source": [
    "**Create the following three models:**\n",
    "* RandomForestClassifier(max depth=15)\n",
    "* BaggingClassifier(base estimator=DecisionTreeClassifier(max depth=15))\n",
    "* AdaBoostClassifier(base estimator=DecisionTreeClassifier(max depth=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# creation of RandomForestClassifier\n",
    "random_forest_classifier = RandomForestClassifier(max_depth = 15)\n",
    "decision_tree_classifier = DecisionTreeClassifier(max_depth = 15)\n",
    "# creation of BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=decision_tree_classifier)\n",
    "#creation of AdaBoostClassifier\n",
    "ada_boost_classifier = AdaBoostClassifier(base_estimator=decision_tree_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ywxf7kfWJBH1"
   },
   "source": [
    "**Tune the following hyper-parameters of the estimators in all ensemble models using grid search:**\n",
    "* n estimators\n",
    "* max features -> for the base estimators\n",
    "* min impurity decrease -> for the base estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2SraPXu6I6qT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 4, 'min_impurity_decrease': 0.0001, 'n_estimators': 159}\n"
     ]
    }
   ],
   "source": [
    "# tuning the parameters for RandomForestClassifier\n",
    "param_grid = {'n_estimators': np.linspace(10, 200,num=15,dtype=int),\n",
    "              'max_features': list(range(1, 5)),\n",
    "              'min_impurity_decrease': [0.0001,0.00025,0.0005,0.001,0.0025,0.005,0.01]}\n",
    "# creation of grid search and fit it\n",
    "grid_search_clf = GridSearchCV(estimator = random_forest_classifier\n",
    "                               , param_grid=param_grid, cv = 5, n_jobs = -1).fit(X_train,y_train)\n",
    "# saving best parameters\n",
    "random_forest_classifier_best = grid_search_clf.best_params_\n",
    "print(random_forest_classifier_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tuning the parameters for BaggingClassifier\n",
    "param_grid = {'n_estimators': np.linspace(10, 200,num=15,dtype=int),\n",
    "              'base_estimator__max_features': list(range(1, 5)),\n",
    "              'base_estimator__min_impurity_decrease': [0.0001,0.00025,0.0005,0.001,0.0025,0.005,0.01]}\n",
    "# creation of grid search and fit it\n",
    "grid_search_clf = GridSearchCV(estimator = bagging_classifier\n",
    "                               , param_grid=param_grid, cv = 5, n_jobs = -1).fit(X_train,y_train)\n",
    "# saving best parameters\n",
    "bagging_classifier_best = grid_search_clf.best_params_\n",
    "print(bagging_classifier_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tuning the parameters for AdaBoostClassifier\n",
    "param_grid = {'n_estimators': np.linspace(10, 200,num=15,dtype=int),\n",
    "              'base_estimator__max_features': list(range(1, 5)),\n",
    "              'base_estimator__min_impurity_decrease': [0.0001,0.00025,0.0005,0.001,0.0025,0.005,0.01]}\n",
    "# creation of grid search and fit it\n",
    "grid_search_clf = GridSearchCV(estimator = ada_boost_classifier\n",
    "                               , param_grid=param_grid, cv = 5, n_jobs = -1).fit(X_train,y_train)\n",
    "# saving best parameters\n",
    "ada_boost_classifier_best = grid_search_clf.best_params_\n",
    "print(ada_boost_classifier_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl8tAaRksrfM"
   },
   "source": [
    "**Create the final models using the best values of the hyper-parameters and evaluate your models on the test set. Which model performed the best on the test set? Why do you think that is the case?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYsnFpUtDrkv"
   },
   "outputs": [],
   "source": [
    "#Random Forest model with best hyper-parameters\n",
    "n_estimators_best = random_forest_classifier_best['n_estimators']\n",
    "max_features_best = random_forest_classifier_best['max_features']\n",
    "min_impurity_best = random_forest_classifier_best['min_impurity_decrease']\n",
    "random_forest_best = RandomForestClassifier(n_estimators=n_estimators_best, max_depth=15\n",
    "                                       ,max_features=max_features_best,min_impurity_decrease=min_impurity_best).fit(X_train,y_train)\n",
    "y_pred = random_forest_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Bagging Classifier model with best hyper-parameters\n",
    "n_estimators_best1 = bagging_classifier_best['n_estimators']\n",
    "max_features_best1 = bagging_classifier_best['base_estimator__max_features']\n",
    "min_impurity_best1 = bagging_classifier_best['base_estimator__min_impurity_decrease']\n",
    "bagging_tree = DecisionTreeClassifier(max_depth=15, max_features=max_features_best1,min_impurity_decrease=min_impurity_best1)\n",
    "bagging_best = BaggingClassifier(base_estimator=bagging_tree, n_estimators=n_estimators_best1).fit(X_train,y_train)\n",
    "y_pred_bag = bagging_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_bag)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#AdaBoost Classifier model with best hyper-parameters\n",
    "n_estimators_best2 = ada_boost_classifier_best['n_estimators']\n",
    "max_features_best2 = ada_boost_classifier_best['base_estimator__max_features']\n",
    "min_impurity_best2 = ada_boost_classifier_best['base_estimator__min_impurity_decrease']\n",
    "ada_tree = DecisionTreeClassifier(max_depth=15, max_features=max_features_best2,min_impurity_decrease=min_impurity_best2)\n",
    "ada_boost_best = AdaBoostClassifier(base_estimator=ada_tree, n_estimators=n_estimators_best2).fit(X_train,y_train)\n",
    "y_pred_ada = ada_boost_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_ada)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result of models we see that best preformance is made by AdaBoostClassifier.\n",
    "It might be caused because of the most suitable depth for Ada Boost, comparing to other classifiers.\n",
    "It is probable, that on other depths AdaBoost will perform worse. Also, I want to mention that\n",
    "difference of accuracy between classifiers isn't so big, due to good hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer this question before doing the next part. If you fine-tuned the hyper-parameter max depth as\n",
    "well, which of the three ensemble models would you expect to have deeper (larger max depth value)\n",
    "base learners and which would have shallower base learners? Why do you think that would be the\n",
    "case?**\n",
    "\n",
    "Answer:\n",
    "In my opinion, according to the results of previous task AdaBoost is going to have a shallower max_depth,\n",
    "because it performed worse in comparison with other models on max_depth=15. On the other hand, probably\n",
    "RandomForest and Bagging Classifiers are going to be more successeful on deeper max_depth values. The reason\n",
    "for that is AdaBoost becoming more overfitted on higher max_depthes, as in previous tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the models with the best parameters you got from the third step. Fine tune max depth from\n",
    "5 to 25. Draw 3 plots on the same graph. Put the max depth parameter on the horizontal axis and\n",
    "the cross validation accuracy of your ensemble models on the vertical axis. Do the results agree with\n",
    "your answer in the previous part?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_depth_range = list(range(5, 26))\n",
    "cross_val_Random_forest = []\n",
    "cross_val_Bagging = []\n",
    "cross_val_AdaBoost = []\n",
    "for i in max_depth_range:\n",
    "    random_forest_classifier_new = RandomForestClassifier(n_estimators=n_estimators_best, max_depth=i\n",
    "                                       ,max_features=max_features_best,min_impurity_decrease=min_impurity_best)\n",
    "    random_graph = np.mean(cross_val_score(random_forest_classifier_new, X_train, y_train,\n",
    "                             cv=5, scoring='accuracy'))\n",
    "    cross_val_Random_forest.append(random_graph)\n",
    "    bagging_tree_new = DecisionTreeClassifier(max_depth=i, max_features=max_features_best1,min_impurity_decrease=min_impurity_best1)\n",
    "    bagging_classifier_new = BaggingClassifier(base_estimator=bagging_tree_new, n_estimators=n_estimators_best1)\n",
    "    bagging_graph = np.mean(cross_val_score(bagging_classifier_new, X_train, y_train,\n",
    "                             cv=5, scoring='accuracy'))\n",
    "    cross_val_Bagging.append(bagging_graph)\n",
    "    ada_tree_new = DecisionTreeClassifier(max_depth=i, max_features=max_features_best2,min_impurity_decrease=min_impurity_best2)\n",
    "    ada_boost_classifier_new = AdaBoostClassifier(base_estimator=ada_tree_new, n_estimators=n_estimators_best2)\n",
    "    ada_graph = np.mean(cross_val_score(ada_boost_classifier_new, X_train, y_train,\n",
    "                             cv=5, scoring='accuracy'))\n",
    "    cross_val_AdaBoost.append(ada_graph)\n",
    "\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.plot(max_depth_range,cross_val_Random_forest,label='RandomForestClassifier')\n",
    "plt.plot(max_depth_range,cross_val_Bagging,label='BaggingClassifier')\n",
    "plt.plot(max_depth_range,cross_val_AdaBoost,label='AdaBoostClassifier')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**According to results, RandomForest and Bagging Classifiers really neeeded deeper max_depth, however adaboost is working well on small max_depthes, and starts overfitting after**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Task on CNN\n",
    "\n",
    "**Preprocess and visualize the dataset:**\n",
    "##### Download dataset. Description of folders and naming are inside dataset folder in README.txt\n",
    "##### Read all images and convert them to gray with (cv2.ctvColor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = 'images/'\n",
    "images = []\n",
    "for x in range(1,104):\n",
    "    for y in range(1,13):\n",
    "        if(x<10 and y<10):\n",
    "            gray_photo = cv2.imread(src+'00'+str(x)+'_0'+str(y)+'.png')\n",
    "            images.append(cv2.cvtColor(gray_photo,cv2.COLOR_BGR2GRAY))\n",
    "        elif(x<10 and y>=10):\n",
    "            gray_photo = cv2.imread(src+'00'+str(x)+'_'+str(y)+'.png')\n",
    "            images.append(cv2.cvtColor(gray_photo,cv2.COLOR_BGR2GRAY))\n",
    "        elif(x>=10 and x<100 and y<10):\n",
    "            gray_photo = cv2.imread(src+'0'+str(x)+'_0'+str(y)+'.png')\n",
    "            images.append(cv2.cvtColor(gray_photo,cv2.COLOR_BGR2GRAY))\n",
    "        elif(x>=10 and x<100 and y>=10):\n",
    "            gray_photo = cv2.imread(src+'0'+str(x)+'_'+str(y)+'.png')\n",
    "            images.append(cv2.cvtColor(gray_photo,cv2.COLOR_BGR2GRAY))\n",
    "        elif(x>=100 and y<10):\n",
    "            gray_photo = cv2.imread(src+str(x)+'_0'+str(y)+'.png')\n",
    "            images.append(cv2.cvtColor(gray_photo,cv2.COLOR_BGR2GRAY))\n",
    "        elif(x>=100 and y>=10):\n",
    "            gray_photo = cv2.imread(src+str(x)+'_'+str(y)+'.png')\n",
    "            images.append(cv2.cvtColor(gray_photo,cv2.COLOR_BGR2GRAY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read annotation for images. It contains eye corners and eye centers of 2 eyes for each image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "src = 'labels/image_labels.txt'\n",
    "with open(src) as file_in:\n",
    "    lines = []\n",
    "    for line in file_in:\n",
    "        lines.append(line.split())\n",
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize one image, draw eye corners and iris centers on it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = images[0].copy()\n",
    "#direct converting from str to int is not possible because there are irrational numbers\n",
    "x_left = (int(float(lines[0][1])),int(float(lines[0][2])))\n",
    "y_left = (int(float(lines[0][5])),int(float(lines[0][6])))\n",
    "x_right = (int(float(lines[0][7])),int(float(lines[0][8])))\n",
    "y_right = (int(float(lines[0][11])),int(float(lines[0][12])))\n",
    "x_irleft = int(float(lines[0][3]))\n",
    "x_irright = int(float(lines[0][9]))\n",
    "y_irleft = int(float(lines[0][4]))\n",
    "y_irright = int(float(lines[0][10]))\n",
    "image = cv2.rectangle(image, x_left,y_left, color = (250, 255, 219), thickness = 1)\n",
    "image =cv2.rectangle(image, x_right,y_right, color = (250, 255, 219), thickness = 1)\n",
    "image = cv2.circle(image, (x_irleft,y_irleft), radius=0, color=(250, 255, 219), thickness=-1)\n",
    "image = cv2.circle(image, (x_irright,y_irright), radius=0, color=(250, 255, 219), thickness=-1)\n",
    "plt.imshow(image, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize images (divide by 255)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    images[i] = images[i]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check if normalization went well for image\n",
    "plt.imshow(images[0], cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crop eye regions (and resize if needed) to be (48x48) image with the help of eye corners. Do that\n",
    "for all images. It should look like Figure3(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "small_images = []\n",
    "image_num = 0\n",
    "i = 0\n",
    "while i<len(lines):\n",
    "    x1 = int(float(lines[i][1]))\n",
    "    y1 = int(float(lines[i][2]))\n",
    "    x3 = int(float(lines[i][5]))\n",
    "    y3 = int(float(lines[i][6]))\n",
    "    x4 = int(float(lines[i][7]))\n",
    "    y4 = int(float(lines[i][8]))\n",
    "    x6 = int(float(lines[i][11]))\n",
    "    y6 = int(float(lines[i][12]))\n",
    "    point1 = int((x1+x3)/2-24)\n",
    "    point1_1 = int((x1+x3)/2+24)\n",
    "    point2 = int((y1+y3)/2-24)\n",
    "    point2_1 = int((y1+y3)/2+24)\n",
    "    point3 = int((x4+x6)/2-24)\n",
    "    point3_1 = int((x4+x6)/2+24)\n",
    "    point4 = int((y4+y6)/2-24)\n",
    "    point4_1 = int((y4+y6)/2+24)\n",
    "    small_image_left = images[image_num][point2:point2_1,point1:point1_1]\n",
    "    small_image_right = images[image_num][point4:point4_1,point3:point3_1]\n",
    "    small_images.append(small_image_left.reshape(48,48,1))\n",
    "    small_images.append(small_image_right.reshape(48,48,1))\n",
    "    image_num+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check if cropping went well for image\n",
    "plt.imshow(small_images[5],cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now data is ready to create a final dataset, which you will use for CNN training.Your labels (Y) are coordinates of eye center for each image in X (don't forget to convert iris\n",
    "center from whole image coordinate system to coordinate system of eye region). You should make\n",
    "one more step to cook Y set. For each eye center in Y you should create a (48x48) image (with\n",
    "zero values) and assign value=1 to pixel which coordinate is an iris center. Do it for all images.\n",
    "It should look like Figure3(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "small_images_of_iris = []\n",
    "def det_iris(a,b,c,d,e):\n",
    "    f=[]\n",
    "    x_ir = abs(c-a)\n",
    "    y_ir = (48-(abs(d-b)+abs(d-e)))/2\n",
    "    f.append(x_ir)\n",
    "    f.append(y_ir)\n",
    "    return f\n",
    "image_num_iris = 0\n",
    "i = 0\n",
    "while i<len(lines):\n",
    "    x1 = int(float(lines[i][1]))\n",
    "    y1 = int(float(lines[i][2]))\n",
    "    x2 = int(float(lines[i][3]))\n",
    "    y2 = int(float(lines[i][4]))\n",
    "    x3 = int(float(lines[i][5]))\n",
    "    y3 = int(float(lines[i][6]))\n",
    "    x4 = int(float(lines[i][7]))\n",
    "    y4 = int(float(lines[i][8]))\n",
    "    x5 = int(float(lines[i][9]))\n",
    "    y5 = int(float(lines[i][10]))\n",
    "    x6 = int(float(lines[i][11]))\n",
    "    y6 = int(float(lines[i][12]))\n",
    "    point1 = int(abs(x2-x1))\n",
    "    point1_1 = int((48-(abs(y2-y1)+abs(y3-y1)))/2)\n",
    "    point2 = int(abs(x5-x4))\n",
    "    point2_1 = int((48-(abs(y5-y4)+abs(y6-y4)))/2)\n",
    "    small_image_iris_left = np.zeros((48,48),dtype=np.uint8)\n",
    "    small_image_iris_right = np.zeros((48,48),dtype=np.uint8)\n",
    "    small_image_iris_left[point1_1,point1] = 1\n",
    "    small_image_iris_left[point1_1-1,point1] = 1\n",
    "    small_image_iris_left[point1_1+1,point1] = 1\n",
    "    small_image_iris_left[point1_1,point1-1] = 1\n",
    "    small_image_iris_left[point1_1,point1+1] = 1\n",
    "    small_image_iris_right[point2_1,point2] = 1\n",
    "    small_image_iris_right[point2_1,point2-1] = 1\n",
    "    small_image_iris_right[point2_1,point2+1] = 1\n",
    "    small_image_iris_right[point2_1-1,point2] = 1\n",
    "    small_image_iris_right[point2_1+1,point2] = 1\n",
    "    small_images_of_iris.append(small_image_iris_left.reshape(48,48,1))\n",
    "    small_images_of_iris.append(small_image_iris_right.reshape(48,48,1))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check if iris is ok\n",
    "plt.imshow(small_images_of_iris[5],cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X2 = np.asarray(small_images,np.ndarray).reshape(len(small_images),48,48,1)\n",
    "y2 = np.asarray(small_images_of_iris,np.ndarray).reshape(len(small_images_of_iris),48,48,1)\n",
    "X2 = X2.astype(np.float32)\n",
    "y2 = y2.astype(np.float32)\n",
    "print(y2.shape)\n",
    "print(X2.shape)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X2,y2,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a CNN model using Keras. Layers that might be helpful: Conv2, Conv2DTranspose, concatenate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layer1 = Input((48,48,1))\n",
    "layer2 = Conv2D(64, (3,3), strides=(1,1), padding='same', activation= 'relu')(layer1)\n",
    "layer2 = BatchNormalization()(layer2)\n",
    "layer3 = Conv2D(128, (3,3), strides=(2,2), padding='same', activation= 'relu')(layer2)\n",
    "layer3 = BatchNormalization()(layer3)\n",
    "layer4 = Conv2D(256, (3,3), strides=(2,2), padding='same', activation= 'relu')(layer3)\n",
    "layer4 = BatchNormalization()(layer4)\n",
    "layer4_1 = Conv2D(256, (3,3), strides=(1,1), padding='same', activation= 'relu')(layer4)\n",
    "layer4_1 = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', activation= 'relu')(layer4_1)\n",
    "layer4_1 = Conv2DTranspose(64, (3,3), strides=(2,2),padding='same', activation= 'relu')(layer4_1)\n",
    "layer4_1 = Conv2DTranspose(1, (3,3), strides=(1,1), padding='same', activation= 'relu')(layer4_1)\n",
    "layer5 = Conv2DTranspose(128, (3,3), strides=(4,4),padding='same', activation= 'relu')(layer4)\n",
    "layer6 = concatenate(inputs=[layer2,layer5],axis=3)\n",
    "layer6 = BatchNormalization()(layer6)\n",
    "layer7 = Conv2DTranspose(64, (3,3),padding='same', activation= 'relu')(layer6)\n",
    "layer7 = BatchNormalization()(layer7)\n",
    "layer8 = Conv2DTranspose(1, (3,3),padding='same', activation= 'relu')(layer7)\n",
    "\n",
    "model = Model(inputs = layer1, outputs = [layer8,layer4_1])\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss = 'mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile and train CNN with different optimizers [sgd, adam, adamax, rmsprop], loss functions [mse,\n",
    "mae] and activations [tanh, relu, sigmoid]. Report best combination.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train1, [y_train1,X_train1], epochs =  15 ,validation_split=0.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a prediction for 10 test images. Draw predicted centers on them and visualize it. (You can draw\n",
    "iris center with cv2.circle())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(X_test1)\n",
    "for i in range(10):\n",
    "    dot = 0\n",
    "    coor1 = 0\n",
    "    coor2 = 0\n",
    "    for j in range(len(y_pred1[0][i])):\n",
    "        for f in range(0,48):\n",
    "            if(y_pred1[0][i][j][f]>dot):\n",
    "                dot = y_pred1[0][i][j][f]\n",
    "                coor1 = j\n",
    "                coor2 = f\n",
    "    im_to_show = y_pred1[1][i].copy()\n",
    "    im_to_show = cv2.circle(im_to_show,(coor2,coor1),1,(0,0,0))\n",
    "    plt.imshow(im_to_show,cmap = plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above you see that there are 15 epoches running in fit, but I made more epoches before, and retrained model by 15\n",
    "every run, to know when model starts working well. So, don't think that there was only 15 epoches. Accuracy of irises\n",
    "are not ideal, and reason for this can be - small pixel(3х3 cross) for iris in initial data**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practical Tasks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
